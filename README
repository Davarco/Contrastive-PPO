Contrastive Pre-Training for Reinforcement Learning

We tackle sample-efficiency and generalization in RL using contrastive pretraining. We test our results on the FruitBot
game from OpenAI's ProcGen environments, which are specifically designed to evaluate these metrics. 

Our model is split into two parts. First, there is a game state encoder which turns an image into a feature vector. The
actor and critic network are just a linear layer on top of these features. When training the contrastive loss, we reuse
the encoder and use augmented images from FruitBot. More details can be found in our final report. With regards to data
augmentations, we find that crops + color distortion works best. 

To setup the project, create a conda environment and run 'pip install -r requirements.txt'

To run our experiments, run each command in experiments.sh. The models are saved to the models/ dir, while the
tensorboard logs are saved in the logs/ dir. All the code is in the PPO directory.
